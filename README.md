# teach-yourself-ai

üë©‚Äçüî¨ documenting my efforts to learn ai/ml &amp; get a sweet $15m seed round because i use the word vector a lot üí∞

## why?

The emerging disciplines of AI and ML can seem overwhelming, especially for self-taught developers and/or bootcamp grads. It's hard to find the correct signals amongst the sheer amount of misinformation, hype, conjecture and general noise around the industry right now.

This repo is my attempt to log any recommended resources I've used to make sense of it all. I am not intending to necessarily take the shortest route to be dangerous, but instead to develop a solid foundational knowledge. The intended reference point is a comfortable software engineer, although the definition of _comfortable_ is an exercise for the reader.

## warming up in an abstract space

### environment

I appreciate [anaconda](https://www.anaconda.com/) but it's never quite sat right with me. That said, if you're looking for a low-friction approach you probably can't go wrong with it.

Meanwhile, if you've never met a yak you didn't think could do with a shave: 

- python via [mise-en-place](https://mise.jdx.dev/)
- [jupyterlab](https://jupyter.org/) via [pipx](https://github.com/pypa/pipx)

## books

- [How AI Works: From Sorcery To Science](https://nostarch.com/how-ai-works) - Ronald T. Kneusel

## math

- [Linear Algebra for Machine Learning and Data Science](https://www.coursera.org/learn/machine-learning-linear-algebra) - Coursera / DeepLearning.ai

## videos

- [But what is a GPT? Visual intro to transformers](https://youtu.be/wjZofJX0v4M?feature=shared) - 3Blue1Brown

## academic papers

- [Attention Is All You Need (2017)](https://proceedings.neurips.cc/paper_files/paper/2017/file/3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf)
- [On The Opportunities And Risks Of Foundation Models](https://arxiv.org/abs/2108.0725)
- [Efficient Memory Management for Large Language Model Serving with PagedAttention](https://arxiv.org/pdf/2309.06180)
